{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba5d29a-5157-41e8-832c-1682d04be84d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data preview:\n",
      "   source  target  rating        time\n",
      "0    7188       1      10  1407470400\n",
      "1     430       1      10  1376539200\n",
      "2    3134       1      10  1369713600\n",
      "3    3026       1      10  1350014400\n",
      "4    3010       1      10  1347854400\n",
      "\n",
      "Missing values in each column:\n",
      "source    0\n",
      "target    0\n",
      "rating    0\n",
      "time      0\n",
      "dtype: int64\n",
      "\n",
      "Data types before conversion:\n",
      "source    int64\n",
      "target    int64\n",
      "rating    int64\n",
      "time      int64\n",
      "dtype: object\n",
      "\n",
      "Data types after conversion:\n",
      "source             int64\n",
      "target             int64\n",
      "rating             int64\n",
      "time      datetime64[ns]\n",
      "dtype: object\n",
      "\n",
      "Summary statistics for numerical columns:\n",
      "             source        target        rating                           time\n",
      "count  24186.000000  24186.000000  24186.000000                          24186\n",
      "mean     864.029314   1051.093815      1.463946  2012-09-08 10:04:14.825105408\n",
      "min        1.000000      1.000000    -10.000000            2010-11-08 05:00:00\n",
      "25%       58.000000     66.000000      1.000000            2011-08-07 04:00:00\n",
      "50%      238.000000    279.000000      1.000000            2012-08-20 04:00:00\n",
      "75%      898.000000   1068.000000      2.000000            2013-05-25 04:00:00\n",
      "max     7604.000000   7604.000000     10.000000            2016-01-22 05:00:00\n",
      "std     1592.085638   1871.765504      2.903656                            NaN\n",
      "\n",
      "Network statistics:\n",
      "Number of nodes: 3783\n",
      "Number of edges: 14124\n",
      "Processed data has been saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "# Load the dataset directly from a CSV file\n",
    "file_path = 'soc-sign-bitcoinalpha.csv'\n",
    "data = pd.read_csv(file_path, header=None, names=['source', 'target', 'rating', 'time'])\n",
    "\n",
    "# Display the first few rows of the data to understand its structure\n",
    "print(\"Initial data preview:\")\n",
    "print(data.head())\n",
    "\n",
    "# Check for any missing values in the dataset\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# If there are missing values, you might choose to drop them or fill them\n",
    "# For example, if missing values are few, you could drop them\n",
    "# data.dropna(inplace=True)\n",
    "\n",
    "# Alternatively, if 'rating' or 'time' have missing values, decide on a filling strategy\n",
    "# For example:\n",
    "# data['rating'].fillna(data['rating'].mean(), inplace=True)\n",
    "# data['time'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Check data types and convert them if necessary\n",
    "print(\"\\nData types before conversion:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "data['time'] = pd.to_datetime(data['time'], unit='s')  # Assuming 'time' is a UNIX timestamp\n",
    "print(\"\\nData types after conversion:\")\n",
    "print(data.dtypes)\n",
    "\n",
    "# Summary statistics for numerical columns\n",
    "print(\"\\nSummary statistics for numerical columns:\")\n",
    "print(data.describe())\n",
    "\n",
    "# Creating a network graph from the DataFrame\n",
    "G = nx.from_pandas_edgelist(data, 'source', 'target', edge_attr=True)\n",
    "\n",
    "# Basic network statistics\n",
    "print(\"\\nNetwork statistics:\")\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "\n",
    "# Save the cleaned data back to a CSV, if no missing values or after handling them\n",
    "output_file_path = 'cleaned_soc-sign-bitcoinalpha.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Processed data has been saved to CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae4297c4-820f-4f82-bbb2-7e3025cf45c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the top 100 predictions: 0.00%\n",
      "Link prediction completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms.link_prediction import jaccard_coefficient\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cleaned_soc-sign-bitcoinalpha.csv'\n",
    "data = pd.read_csv(file_path, header=None, names=['source', 'target', 'rating', 'time'])\n",
    "\n",
    "# Convert the DataFrame to a graph\n",
    "G = nx.from_pandas_edgelist(data, 'source', 'target', create_using=nx.Graph())\n",
    "\n",
    "# Split data into train and test sets\n",
    "# Here, we randomly remove 10% of edges for testing\n",
    "test_ratio = 0.1\n",
    "edges = list(G.edges())\n",
    "num_test = int(len(edges) * test_ratio)\n",
    "\n",
    "# Make sure the graph remains connected\n",
    "test_edges = []\n",
    "for i in range(num_test):\n",
    "    edge = edges[i]\n",
    "    G.remove_edge(*edge)\n",
    "    if nx.is_connected(G):\n",
    "        test_edges.append(edge)\n",
    "    else:\n",
    "        G.add_edge(*edge)\n",
    "\n",
    "# Link prediction using Jaccard Coefficient\n",
    "pred_jaccard = list(jaccard_coefficient(G))\n",
    "pred_jaccard.sort(key=lambda x: x[2], reverse=True)  # Sort by score\n",
    "\n",
    "# Evaluate the model: Check how many of the top ranked predictions are actually in the test set\n",
    "top_k = 100\n",
    "hits = sum(1 for u, v, p in pred_jaccard[:top_k] if (u, v) in test_edges or (v, u) in test_edges)\n",
    "print(f\"Accuracy of the top {top_k} predictions: {hits/top_k:.2%}\")\n",
    "\n",
    "# Save predictions to a file\n",
    "predictions_df = pd.DataFrame(pred_jaccard, columns=['source', 'target', 'score'])\n",
    "predictions_df.to_csv('link_predictions.csv', index=False)\n",
    "\n",
    "print(\"Link prediction completed and results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51066acf-41e9-447d-a567-a6a2696bc8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the top 100 predictions: 0.00%\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/mnt/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(predictions, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     45\u001b[0m predictions_output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/jaccard_predictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mpredictions_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions_output_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLink prediction completed and results saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, predictions_output_path)\n",
      "File \u001b[0;32m/opt/software/lib/python3.10/site-packages/pandas/core/generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3900\u001b[0m )\n\u001b[0;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/software/lib/python3.10/site-packages/pandas/io/formats/format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1151\u001b[0m )\n\u001b[0;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/opt/software/lib/python3.10/site-packages/pandas/io/formats/csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    264\u001b[0m     )\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/opt/software/lib/python3.10/site-packages/pandas/io/common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/opt/software/lib/python3.10/site-packages/pandas/io/common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '/mnt/data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms.link_prediction import jaccard_coefficient\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'cleaned_soc-sign-bitcoinalpha.csv'\n",
    "data = pd.read_csv(file_path, header=None, names=['source', 'target', 'rating', 'time'])\n",
    "\n",
    "# Convert the DataFrame to a graph\n",
    "G = nx.from_pandas_edgelist(data, 'source', 'target', create_using=nx.Graph())\n",
    "\n",
    "# Example of how to handle splits, assuming the script does this\n",
    "# For the sake of demonstration, let's randomly remove 10% of edges for testing\n",
    "import random\n",
    "random.seed(42)  # For reproducibility\n",
    "edges = list(G.edges())\n",
    "random.shuffle(edges)\n",
    "\n",
    "test_ratio = 0.1\n",
    "num_test = int(len(edges) * test_ratio)\n",
    "train_edges = edges[num_test:]\n",
    "test_edges = edges[:num_test]\n",
    "\n",
    "# Remove test edges from graph\n",
    "G_train = G.copy()\n",
    "G_train.remove_edges_from(test_edges)\n",
    "\n",
    "# Ensure the graph remains connected; this example doesn't handle this but should be considered in a real scenario\n",
    "# Calculate Jaccard Coefficients on the training graph\n",
    "predictions = list(jaccard_coefficient(G_train))\n",
    "predictions.sort(key=lambda x: x[2], reverse=True)  # Sort by Jaccard scores\n",
    "\n",
    "# Evaluate predictions\n",
    "# Let's consider the top-k predictions and see how many are actually in the test set\n",
    "top_k = 100\n",
    "hits = 0\n",
    "for u, v, p in predictions[:top_k]:\n",
    "    if (u, v) in test_edges or (v, u) in test_edges:\n",
    "        hits += 1\n",
    "\n",
    "print(f\"Accuracy of the top {top_k} predictions: {hits/top_k:.2%}\")\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "predictions_df = pd.DataFrame(predictions, columns=['source', 'target', 'score'])\n",
    "predictions_output_path = '/mnt/data/jaccard_predictions.csv'\n",
    "predictions_df.to_csv(predictions_output_path, index=False)\n",
    "\n",
    "print(\"Link prediction completed and results saved to:\", predictions_output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "892049c3-a3fd-465e-b79a-8e7404411a25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dgl\n",
      "  Downloading dgl-2.1.0-cp310-cp310-manylinux1_x86_64.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/software/lib/python3.10/site-packages (from dgl) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/software/lib/python3.10/site-packages (from dgl) (1.11.3)\n",
      "Requirement already satisfied: networkx>=2.1 in /opt/software/lib/python3.10/site-packages (from dgl) (3.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/software/lib/python3.10/site-packages (from dgl) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/software/lib/python3.10/site-packages (from dgl) (4.65.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/software/lib/python3.10/site-packages (from dgl) (5.9.5)\n",
      "Requirement already satisfied: torchdata>=0.5.0 in /opt/software/lib/python3.10/site-packages (from dgl) (0.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/software/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/software/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/software/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/software/lib/python3.10/site-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
      "Requirement already satisfied: torch>=2 in /opt/software/lib/python3.10/site-packages (from torchdata>=0.5.0->dgl) (2.1.1)\n",
      "Requirement already satisfied: filelock in /opt/software/lib/python3.10/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/software/lib/python3.10/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/software/lib/python3.10/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/software/lib/python3.10/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/software/lib/python3.10/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/software/lib/python3.10/site-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/software/lib/python3.10/site-packages (from sympy->torch>=2->torchdata>=0.5.0->dgl) (1.3.0)\n",
      "Installing collected packages: dgl\n",
      "Successfully installed dgl-2.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dcf93e0-4c48-4d48-affc-c20ba08bb40a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.73162841796875\n",
      "Epoch 5, Loss: 0.6965652108192444\n",
      "Epoch 10, Loss: 0.6936313509941101\n",
      "Epoch 15, Loss: 0.6932875514030457\n",
      "Epoch 20, Loss: 0.6933138370513916\n",
      "Epoch 25, Loss: 0.6933148503303528\n",
      "Epoch 30, Loss: 0.6932670474052429\n",
      "Epoch 35, Loss: 0.6932210922241211\n",
      "Epoch 40, Loss: 0.693195104598999\n",
      "Epoch 45, Loss: 0.6931819319725037\n",
      "Epoch 50, Loss: 0.6931743621826172\n",
      "Epoch 55, Loss: 0.6931692361831665\n",
      "Epoch 60, Loss: 0.6931655406951904\n",
      "Epoch 65, Loss: 0.6931628584861755\n",
      "Epoch 70, Loss: 0.6931607723236084\n",
      "Epoch 75, Loss: 0.693159282207489\n",
      "Epoch 80, Loss: 0.6931580305099487\n",
      "Epoch 85, Loss: 0.6931570768356323\n",
      "Epoch 90, Loss: 0.6931563019752502\n",
      "Epoch 95, Loss: 0.6931557655334473\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scipy.sparse as sp\n",
    "import dgl.function as fn\n",
    "\n",
    "\n",
    "# Load the BitcoinAlpha dataset\n",
    "file_path = 'soc-sign-bitcoinalpha.csv'\n",
    "data = pd.read_csv(file_path, header=None, names=['source', 'target', 'rating', 'time'])\n",
    "\n",
    "# Create a graph\n",
    "edges = data[['source', 'target']].to_numpy()\n",
    "g = dgl.graph((edges[:, 0], edges[:, 1]))\n",
    "g = dgl.add_self_loop(g)  # Optionally add self-loops\n",
    "\n",
    "# Since the dataset may not have node features, we create synthetic features (e.g., one-hot encoded)\n",
    "num_nodes = g.number_of_nodes()\n",
    "g.ndata['feat'] = torch.eye(num_nodes)\n",
    "\n",
    "# Define the GraphSAGE model\n",
    "from dgl.nn import SAGEConv\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "\n",
    "# Dot product predictor\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]\n",
    "\n",
    "# Prepare training and testing sets\n",
    "u, v = g.edges()\n",
    "eids = np.random.permutation(g.number_of_edges())\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "\n",
    "# Negative sampling\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "\n",
    "# Training loop\n",
    "model = GraphSAGE(num_nodes, 16)  # num_nodes is used as in_feats for synthetic features\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "\n",
    "for e in range(100):\n",
    "    h = model(g, g.ndata['feat'])\n",
    "    pos_score = pred(g, h)  # Predict on full graph for simplicity\n",
    "    neg_score = pred(g, h)  # Same here, simplify for example purposes\n",
    "    loss = F.binary_cross_entropy_with_logits(torch.cat([pos_score, neg_score]),\n",
    "                                              torch.cat([torch.ones(pos_score.shape[0]),\n",
    "                                                         torch.zeros(neg_score.shape[0])]))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if e % 5 == 0:\n",
    "        print(f'Epoch {e}, Loss: {loss.item()}')\n",
    "\n",
    "# Evaluation (simplified, just to demonstrate)\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(g, h)\n",
    "    neg_score = pred(g, h)\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = np.concatenate([np.ones(pos_score.shape[0]), np.zeros(neg_score.shape[0])])\n",
    "    auc = roc_auc_score(labels, scores)\n",
    "    print('AUC:', auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f67aedb-09d5-4c9c-b9b8-a62ad3e73306",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-igraph\n",
      "  Downloading python_igraph-0.11.4-py3-none-any.whl (9.1 kB)\n",
      "Collecting igraph==0.11.4 (from python-igraph)\n",
      "  Downloading igraph-0.11.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: texttable>=1.6.2 in /opt/software/lib/python3.10/site-packages (from igraph==0.11.4->python-igraph) (1.7.0)\n",
      "Installing collected packages: igraph, python-igraph\n",
      "  Attempting uninstall: igraph\n",
      "    Found existing installation: igraph 0.11.3\n",
      "    Uninstalling igraph-0.11.3:\n",
      "      Successfully uninstalled igraph-0.11.3\n",
      "Successfully installed igraph-0.11.4 python-igraph-0.11.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-igraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d061d66-c2b7-4f6c-951a-185d7f618606",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '{'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 83\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod not recognized. Choose from \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcommon_neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjaccard\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madamic_adar\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreferential_attachment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkatz\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfriendtns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 70\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m method \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     69\u001b[0m dataset_path \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m---> 70\u001b[0m edge_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_edge_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Use one of the local methods or katz/friendtns if specified\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommon_neighbors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjaccard\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madamic_adar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreferential_attachment\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36mget_edge_list\u001b[0;34m(dataset_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_edge_list\u001b[39m(dataset_path):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dataset_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 15\u001b[0m         edge_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m))) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edge_list\n",
      "Cell \u001b[0;32mIn[18], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_edge_list\u001b[39m(dataset_path):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dataset_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m---> 15\u001b[0m         edge_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file \u001b[38;5;28;01mif\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()]\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m edge_list\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '{'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ae7f5-b3a7-4f77-a542-4bf01c184f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
